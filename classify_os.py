# -*- coding: utf-8 -*-
"""classify_os.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TGsajwdnJWFc3M1mtpU7rcccGBGgyEpP
"""

import glob
import os
import pandas            as pd
import numpy             as np
import re
import json
import seaborn           as sns
import matplotlib.pyplot as plt

from sklearn.model_selection         import train_test_split
from sklearn.metrics                 import classification_report, confusion_matrix
from scipy.sparse                    import hstack
from sklearn.preprocessing           import LabelEncoder
from collections.abc                 import MutableMapping, MutableSequence
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics                 import accuracy_score, f1_score
from xgboost                         import XGBClassifier
from sklearn.preprocessing           import OneHotEncoder
from sklearn.pipeline                import Pipeline

### Блок с функциями

## Определение регулярного выражения для поиска операционной системы
def get_os(user_agent):
    if re.search(r'iPhone|iPad', user_agent):
        if re.search(r'Macintosh|Mac OS', user_agent):
            return 'iOS'
        return 'iOS'
    for os_name, pattern in os_patterns.items():
        if re.search(pattern, user_agent):
            return os_name
    return 'Unknown'
#
# Функция для извлечения значения по ключу 'highest'
def get_highest(os_prediction):
    return os_prediction['highest']
#
# Функция для извлечения ОС из HTTP2 и js_fingerprint
os_patterns = {
    'Android': r'Android',
    'Windows': r'Windows NT',
    'Mac OS': r'Macintosh|Mac OS X',
    'iOS': r'iPhone|iPad',
    'Linux': r'Linux'
}

def get_os_http(user_agent):
    if isinstance(user_agent, dict):
        user_agent = str(user_agent)  # Преобразуем словарь в строку
    if not isinstance(user_agent, str) or pd.isna(user_agent):
        return 'Unknown'  # Если это не строка или NaN, возвращаем Unknown
    if re.search(r'iPhone|iPad', user_agent):
        if re.search(r'Macintosh|Mac OS', user_agent):
            return 'iOS'
        return 'iOS'
    for os_name, pattern in os_patterns.items():
        if re.search(pattern, user_agent):
            return os_name
    return 'Unknown'
# Фунцияч для преобразования вложенных структур в строки
def flatten_structure(data):
    tokens = []

    def recursive_flatten(element):
        if isinstance(element, (str, int, float, bool)):
            tokens.append(str(element))
        elif isinstance(element, MutableMapping):  # Если это словарь
            for key, value in element.items():
                tokens.append(str(key))
                recursive_flatten(value)
        elif isinstance(element, MutableSequence):  # Если это список
            for item in element:
                recursive_flatten(item)
        else:
            tokens.append(str(element))

    recursive_flatten(data)
    return ', '.join(tokens)
# Функция принимает грязные данные в JSON и возвращает очищенный датафрейм для обучения модели
def func_EDA(obj,fingers):

        # Транспонируем DataFrame
        obj_t = obj.T
        obj_t = obj_t.rename(columns={'ip':'ip_org'})


        fingers = fingers.drop_duplicates(subset=['ip'])

        v = fingers.copy()
        merge = pd.merge(v,obj_t[['ip_org','score','risk','is_blacklisted_external','isp','organization',]],left_on='ip', right_on='ip_org', how='left')
        merge.drop(columns=['ip_org'], inplace=True)

        merge['organization'] = merge.apply(lambda row: row['isp'] if row['organization'] == 'n/a' else row['organization'], axis=1)
        merge = merge.copy()
        # Применение функции и создание новой колонки 'os'
        merge['os'] = merge['os_prediction'].apply(get_highest)
        merge['u_a_os'] = merge['user_agent'].apply(get_os)

        merge = merge[['organization','ip','http_version','os','u_a_os','tls','tcpip','http2','method',]]

        merge2 = merge[['organization','ip','http_version','method','os','u_a_os','tls','tcpip','http2',]].copy()
        merge2 = merge2.drop_duplicates(subset=['organization'], keep='first')

        merge_filtered2 = merge2[merge2['os'] == merge2['u_a_os']]

        merge_filtered = merge_filtered2.copy()
        ### HTTP2 to text
        merge_filtered.loc[:,'http2_text'] = merge_filtered['http2'].apply(
            lambda x: flatten_structure(x) if isinstance(x, (dict, list)) else flatten_structure(json.loads(x)) if isinstance(x, str) else ''
        )

        merge_filtered.loc[:,'http2_text_cut'] = merge_filtered['http2_text'].str.extract(r'(.*?)(?=\bpayload\b)', expand=False).fillna(merge_filtered['http2_text'])
        ###### TLS to text
        merge_filtered.loc[:,'tls_text'] = merge_filtered['tls'].apply(
            lambda x: flatten_structure(x) if isinstance(x, (dict, list)) else flatten_structure(json.loads(x)) if isinstance(x, str) else ''
        )
        merge_filtered.loc[:,'tls_text'] = merge_filtered['tls_text'].str.extract(r'(.*?)(?=\bextensions\b)', expand=False).fillna(merge_filtered['tls_text'])
        merge_filtered.loc[:, 'tls_text'] = merge_filtered['tls_text'].str.extract(r'ciphers,(.*)', expand=False).fillna(merge_filtered['tls_text'])
        ####### TCP/IP to text

        merge_filtered.loc[:,'tcpip_text'] = merge_filtered['tcpip'].apply(
            lambda x: flatten_structure(x) if isinstance(x, (dict, list)) else flatten_structure(json.loads(x)) if isinstance(x, str) else ''
        )
        ####CHIPERS
        merge_filtered.loc[:,'ja3_hash'] = merge_filtered['tls'].apply(
            lambda x: flatten_structure(x) if isinstance(x, (dict, list)) else flatten_structure(json.loads(x)) if isinstance(x, str) else ''
        )

        # Извлечение хэша ja3, который идет после 'ja3_hash,' и перед ','
        merge_filtered.loc[:,'ja3_hash'] = merge_filtered['ja3_hash'].str.extract(r'ja3_hash,\s*([a-f0-9]{32})\s*,',expand=False)


        # Извлечение строки после 'settings': [' и до ']'
        merge_filtered.loc[:, 'http_settings'] = merge_filtered['http2_text'].str.extract(r'.*settings,(.*?), frame_type, WINDOW_UPDATE,', expand=False).fillna(merge_filtered['http2_text'])
        merge_filtered.loc[:,'text'] = merge_filtered.apply(lambda row: ', '.join([row['tls_text'], row['tcpip_text'], row['ja3_hash'], row['http_settings']]), axis=1)
        # Убираем пробелы после запятых в колонке concatenated
        merge_filtered['text'] = merge_filtered['text'].str.replace(', ', ',', regex=False)
        merge_filtered =  merge_filtered[['os','tls_text','tcpip_text','ja3_hash','http_settings','text',]].copy()
        merge_filtered = merge_filtered.apply(lambda col: col.str.strip().str.rstrip(','))

        return merge_filtered
#
# Функция ,которая принимает датафрейм и обучает модель,возвращая объект model
def xgb_model(data):
       # Разделение данных
    train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['os'], random_state=42)

    # Создаем и обучаем vectorizer
    vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)
    X_train = vectorizer.fit_transform(train_data['text'])
    X_test = vectorizer.transform(test_data['text'])

    # Кодирование целевой переменной
    label_encoder = LabelEncoder()
    y_train = label_encoder.fit_transform(train_data['os'])
    y_test = label_encoder.transform(test_data['os'])

    # Создаем и обучаем модель XGBoost
    model = XGBClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Предсказание
    y_pred_xgb = model.predict(X_test)

    # Оценка модели
    print("XGBoost Classification Report:")
    print(classification_report(y_test, y_pred_xgb, target_names=label_encoder.classes_))

    print("XGBoost Accuracy:", accuracy_score(y_test, y_pred_xgb))
    print("XGBoost F1-score:", f1_score(y_test, y_pred_xgb, average='weighted'))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred_xgb)
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix for XGBoost')
    plt.show()

    # Возвращаем обученные vectorizer и model
    return model,vectorizer,label_encoder
#
# # Функция для предсказания
# def predict_text(text):
#     text_vectorized = vectorizer.transform([text])  # Преобразуем текст в вектор
#     prediction = model.predict(text_vectorized)  # Получаем предсказанный класс
#     return prediction[0]  # Возвращаем сам класс
# #
# #
def predict_data(data,model,vectorizer,label_encoder):
    # Применяем get_os к столбцу user_agent
    data['os'] = data['os_prediction'].apply(get_highest)

    # Выбираем нужные колонки
    data = data[['ip', 'os', 'tls', 'tcpip', 'http2']]

    # Создаем копию данных для обработки
    merge_filtered = data.copy()

    ### HTTP2 to text
    merge_filtered.loc[:, 'http2_text'] = merge_filtered['http2'].apply(
        lambda x: flatten_structure(x) if isinstance(x, (dict, list)) else flatten_structure(json.loads(x)) if isinstance(x, str) else ''
    )

    ###### TLS to text
    merge_filtered.loc[:, 'tls_text'] = merge_filtered['tls'].apply(
        lambda x: flatten_structure(x) if isinstance(x, (dict, list)) else flatten_structure(json.loads(x)) if isinstance(x, str) else ''
    )
    merge_filtered.loc[:, 'tls_text'] = merge_filtered['tls_text'].str.extract(r'(.*?)(?=\bextensions\b)', expand=False).fillna(merge_filtered['tls_text'])
    merge_filtered.loc[:, 'tls_text'] = merge_filtered['tls_text'].str.extract(r'ciphers,(.*)', expand=False).fillna(merge_filtered['tls_text'])

    ####### TCP/IP to text
    merge_filtered.loc[:, 'tcpip_text'] = merge_filtered['tcpip'].apply(
        lambda x: flatten_structure(x) if isinstance(x, (dict, list)) else flatten_structure(json.loads(x)) if isinstance(x, str) else ''
    )

    #### CHIPERS
    merge_filtered.loc[:, 'ja3_hash'] = merge_filtered['tls'].apply(
        lambda x: flatten_structure(x) if isinstance(x, (dict, list)) else flatten_structure(json.loads(x)) if isinstance(x, str) else ''
    )

    # Извлечение хэша ja3, который идет после 'ja3_hash,' и перед ','
    merge_filtered.loc[:, 'ja3_hash'] = merge_filtered['ja3_hash'].str.extract(r'ja3_hash,\s*([a-f0-9]{32})\s*,', expand=False)

    # Извлечение строки после 'settings': [' и до ']'
    merge_filtered.loc[:, 'http_settings'] = merge_filtered['http2_text'].str.extract(r'.*settings,(.*?), frame_type, WINDOW_UPDATE,', expand=False).fillna(merge_filtered['http2_text'])

    # Создаем колонку text
    merge_filtered.loc[:, 'text'] = merge_filtered.apply(lambda row: ', '.join([row['tls_text'], row['tcpip_text'], row['ja3_hash'], row['http_settings']]), axis=1)

    # Убираем пробелы после запятых в колонке text
    merge_filtered['text'] = merge_filtered['text'].str.replace(', ', ',', regex=False)

    # Выбираем нужные колонки
    merge_filtered = merge_filtered[['ip','os', 'text']].copy()

    # Очистка данных
    merge_filtered = merge_filtered.apply(lambda col: col.str.strip().str.rstrip(','))

    X_test = vectorizer.transform(merge_filtered['text'])
    merge_filtered['pred'] =  model.predict(X_test)
     # Преобразуем числовые предсказания обратно в строки
    merge_filtered['pred_os'] = label_encoder.inverse_transform(merge_filtered['pred'])
    to_js = merge_filtered[['ip', 'pred_os']].to_dict(orient='records')

    # Сохраняем список словарей в JSON-файл
    with open('output.json', 'w', encoding='utf-8') as f:
        json.dump(to_js, f, ensure_ascii=False, indent=4)

    print("Данные записаны в output.json")
    return merge_filtered

obj = pd.read_json('organizations.json')
fingers = pd.read_json('fingerprints_with_os_checked.json', lines=True)

data = func_EDA(obj,fingers)

model,vectorizer,label_encoder = xgb_model(data)

# Для предсказания закинул в функцию predict_data()  данные fingers ,т.к других нет

df = predict_data(fingers,model,vectorizer,label_encoder)

df.head()